{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in ./.conda/lib/python3.10/site-packages (4.66.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install yt-dlp\n",
    "# %pip install moviepy\n",
    "# %pip install transformers\n",
    "# %pip install optimum \n",
    "# %pip install accelerate\n",
    "# %pip install whisperplus\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "def get_user_video_urls(username):\n",
    "    video_urls = []\n",
    "    for file in glob.glob(f\"data/{username}/videos/*.json\"):\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "            url = f'https://www.tiktok.com/@{data[\"author\"][\"uniqueId\"]}/video/{data[\"id\"]}'\n",
    "            video_urls.append(url)\n",
    "    return video_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from yt_dlp import YoutubeDL\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "\n",
    "def download_video(url, output_folder='data/spdbt/videos'):\n",
    "    \"\"\"\n",
    "    Downloads a video from TikTok and saves it in the specified folder.\n",
    "\n",
    "    :param url: TikTok video URL.\n",
    "    :param output_folder: Folder where the video will be saved.\n",
    "    :return: Path to the downloaded video.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    video_id = url.split(\"/\")[-1]\n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'best',  # Download the best available quality\n",
    "        'outtmpl': os.path.join(output_folder, f'{video_id}.%(ext)s'),  # Save video with its ID\n",
    "        # 'ffmpeg_location': '/opt/homebrew/bin/ffmpeg',\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        print(f\"Video downloaded and saved in the '{output_folder}' folder.\")\n",
    "        return os.path.join(output_folder, f'{video_id}.mp4')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_audio(video_file_path, bitrate=\"64k\"):\n",
    "    \"\"\"\n",
    "    Extracts audio from a video file and saves it as an MP3 file in the same directory.\n",
    "    \n",
    "    :param video_file_path: Path to the video file.\n",
    "    :param bitrate: Bitrate for the audio file, lower for smaller size.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the video file\n",
    "        video = VideoFileClip(video_file_path)\n",
    "\n",
    "        # Build the output file path\n",
    "        output_file_path = os.path.splitext(video_file_path)[0] + \".mp3\"\n",
    "\n",
    "        # Extract and write the audio\n",
    "        video.audio.write_audiofile(output_file_path, codec='libmp3lame', bitrate=bitrate)\n",
    "\n",
    "        print(f\"Audio extracted successfully and saved to {output_file_path}\")\n",
    "        return output_file_path\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# tiktok_url = 'https://www.tiktok.com/@spdbt/video/7047893921757809926'\n",
    "# path = download_video(tiktok_url)\n",
    "# audio_path = extract_audio(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "def worker(video_queue, username):\n",
    "    while not video_queue.empty():\n",
    "        url = video_queue.get()\n",
    "        download_and_process_video(url, username)\n",
    "        video_queue.task_done()\n",
    "\n",
    "def download_and_process_video(url, username):\n",
    "    path = download_video(url, output_folder=f\"data/{username}/videos\")\n",
    "    audio_path = extract_audio(path)\n",
    "    # transcript = extract_transcript(audio_path)\n",
    "    # store_transcript(transcript, path.replace(\".mp4\", \".txt\"))\n",
    "\n",
    "chunk_size = 10  # Number of videos to process in each chunk\n",
    "\n",
    "for username in os.listdir(\"data\"):\n",
    "    if username == \".DS_Store\":\n",
    "        continue\n",
    "\n",
    "    video_urls = get_user_video_urls(username)\n",
    "    print(f\"Found {len(video_urls)} videos for user {username}\")\n",
    "\n",
    "    video_ids = [url.split(\"/\")[-1] for url in video_urls]\n",
    "    downloaded_videos = glob.glob(f\"data/{username}/videos/*.mp3\")\n",
    "    downloaded_video_ids = [os.path.basename(path).replace(\".mp3\", \"\") for path in downloaded_videos]\n",
    "    video_urls = [url for url in video_urls if url.split(\"/\")[-1] not in downloaded_video_ids]\n",
    "    print(f\"Downloading {len(video_urls)} videos for user {username}\")\n",
    "\n",
    "    for i in range(0, len(video_urls), chunk_size):\n",
    "        video_queue = Queue()\n",
    "        threads = []\n",
    "\n",
    "        for url in video_urls[i:i + chunk_size]:\n",
    "            video_queue.put(url)\n",
    "\n",
    "        for _ in range(min(chunk_size, video_queue.qsize())):\n",
    "            thread = threading.Thread(target=worker, args=(video_queue, username))\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        video_queue.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634\n",
      "1618\n",
      "1624\n",
      "1623\n"
     ]
    }
   ],
   "source": [
    "# count number of mp3 files in folder\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "path = 'data/*/*/'\n",
    "\n",
    "json_files = glob.glob(os.path.join(path, '*.json'))\n",
    "mp4_files = glob.glob(os.path.join(path, '*.mp4'))\n",
    "mp3_files = glob.glob(os.path.join(path, '*.mp3'))\n",
    "txt_files = glob.glob(os.path.join(path, '*.txt'))\n",
    "print(len(json_files))\n",
    "print(len(mp4_files))\n",
    "print(len(mp3_files))\n",
    "print(len(txt_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the diggcount of the videos for each username over time\n",
    "# show diggcount in 1000s\n",
    "# plot all usernames in one plot\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "usernames = os.listdir(\"data\")\n",
    "\n",
    "usernames.remove(\".DS_Store\")\n",
    "\n",
    "def get_diggCounts(username):\n",
    "    diggcounts = []\n",
    "    dates = []\n",
    "    for file in glob.glob(f\"data/{username}/videos/*.json\"):\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "            diggcount = data[\"stats\"][\"diggCount\"]\n",
    "            diggcounts.append(diggcount)\n",
    "            date = data[\"createTime\"]\n",
    "            dates.append(date)\n",
    "    return diggcounts, dates\n",
    "\n",
    "map_users = {}\n",
    "\n",
    "for username in usernames:\n",
    "    diggcounts, dates = get_diggCounts(username)\n",
    "    map_users[username] = {}\n",
    "    map_users[username][\"diggcounts\"] = diggcounts\n",
    "    map_users[username][\"dates\"] = dates\n",
    "\n",
    "# safe to json\n",
    "import json\n",
    "\n",
    "with open('map_users.json', 'w') as fp:\n",
    "    json.dump(map_users, fp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all infos in one json\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "usernames = os.listdir(\"data\")\n",
    "\n",
    "usernames.remove(\".DS_Store\")\n",
    "\n",
    "video_list = []\n",
    "\n",
    "for username in usernames:\n",
    "    for file in glob.glob(f\"data/{username}/videos/*.json\"):\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "            new_data = {}\n",
    "            new_data[\"id\"] = data[\"id\"]\n",
    "            new_data[\"createTime\"] = data[\"createTime\"]\n",
    "            new_data[\"diggCount\"] = data[\"stats\"][\"diggCount\"]\n",
    "            new_data[\"shareCount\"] = data[\"stats\"][\"shareCount\"]\n",
    "            new_data[\"playCount\"] = data[\"stats\"][\"playCount\"]\n",
    "            new_data[\"commentCount\"] = data[\"stats\"][\"commentCount\"]\n",
    "            new_data[\"author\"] = username\n",
    "            new_data[\"duration\"] = data[\"video\"][\"duration\"]\n",
    "\n",
    "            video_list.append(new_data)\n",
    "\n",
    "# safe to json\n",
    "import json\n",
    "\n",
    "with open('list_videos.json', 'w') as fp:\n",
    "    json.dump(video_list, fp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'diggcount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Uni/Seminar/tiktok_crawler/.conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'diggcount'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# convert to pandas dataframe\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Filter out non-numeric values in the \"diggcount\" column\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiggcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39misdigit())]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Convert the \"diggcount\" column to float\u001b[39;00m\n\u001b[1;32m     23\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiggcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiggcount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Uni/Seminar/tiktok_crawler/.conda/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/Uni/Seminar/tiktok_crawler/.conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'diggcount'"
     ]
    }
   ],
   "source": [
    "# analyze the correlation between the diggcount and the other features\n",
    "# plot the correlation matrix\n",
    "# plot the correlation matrix for each username\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# load the data\n",
    "with open('list_videos.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiktok_crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
